## Efficient Learning

In our main paper, we show results for efficient learning in section 4.5, which we provide code to reproduce our results.

### 1. Installation
Since the efficient learning takes the original detectron2 evaulation metrics for evaualtion of the instance segmentation,
semantic segmentation and panoptic segmentatin, while our U2Seg build on our own evaulation based on that, the main branch of U2Seg repo is adapted for specific use
for U2Seg. In order to evaluate the efficient learning, users need to build a clean environment with the following steps.

#### Create a conda environment
```angular2html
conda create --name u2seg_eff python=3.8.1
conda activate u2seg_eff
```

#### Install the Pytorch

```angular2html
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu11
```
* Might need to be modified based on your available hardware, GPU and CUDA.

#### build this repo
```angular2html
git clone this repo
cd this repo
pip install -e.
```

### 2. Dataset Preparason
Follwing the offical detectron2 dataset saving structure, user should
download the MS COCO dataset and save it as:

```angular2html
U2Seg_eff/detectron2/
                    datasets/
                        coco/
                            annotations/
                                        panoptic_{train, val}2017.json
                                        coco-semi/
                                                {1, 5, 10, 20, 30, 40, 50}perc_instances_train2017.json
                            {train, val}2017/
                                            163330523.jpg
                                            163330524.jpg
                                            ...
                            panoptic_stuff_{train, val}2017
                            panoptic_{train, val}2017

                    
```

* Note that the ```panoptic_stuff_{train, val}2017``` needs to be generated by users following running the offical ```detectron2/datasets/prepare_panoptic_fpn.py```.
* we provide coco-semi in [link](https://drive.google.com/file/d/1Q67cZukGX4t2bqmV1GOmz2ntPbDzH9r7/view?usp=sharing) that the user can download.

### 3. Running the Efficient Learning

By using the different percentage supervision, the user can reproduce the results in the main paper by running:

```angular2html
python tools/train_net.py --config-file detectron2/configs/COCO-PanopticSegmentation/efficiency_1per.yaml \
```
* Remember to edit the ```WEIGHTS``` in the yaml file, a good option is use our ```cocotrain_300_0089999.pth```
from our Model Zoo.

* If you need to reproduce other percentage, you should edit ```detectron2/detectron2/data/datasets/builtin.py``` [line 55](https://github.com/Dantong88/U2Seg_eff/blob/69edafb46801abc51848becb5195b66bfd9e5d72/detectron2/detectron2/data/datasets/builtin.py#L55) to the corresponding percentage json file we provided in the data preparason section.
  
* We use 8 gpus and the batch size is 16. Remember to customize your batch size, lr and training steps to equal the setting based on your GPU access situation.

* After running this, you should be able to get the similar number for evaluation on COCO Val 2017 panoptic segmantation task.
